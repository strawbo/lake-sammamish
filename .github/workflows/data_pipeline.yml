name: Fetch and Import Lake Data

permissions:
  contents: write

on:
  schedule:
    - cron: "0 */4 * * *"  # Runs every 4 hours
  workflow_dispatch:  # Allow manual execution

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set Up Python
        uses: actions/setup-python@v3
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: pip install requests psycopg2 python-dotenv beautifulsoup4 sqlalchemy pandas

      - name: Run Data Fetch Script
        env:
          SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
        run: python scripts/download_data.py

      - name: Run Import Script
        env:
          SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
        run: python scripts/import_data.py

      - name: Generate HTML
        env:
          SUPABASE_DB_URL: ${{ secrets.SUPABASE_DB_URL }}
        run: python scripts/generate_html.py

      - name: Push updated index.html
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git remote set-url origin https://x-access-token:${{ secrets.GH_PAT }}@github.com/strawbo/lake-sammamish.git
          git add docs/index.html
          git commit -m "Auto-update index.html" || echo "No changes to commit"
          git push origin main
        env:
          GH_PAT: ${{ secrets.GH_PAT }}
